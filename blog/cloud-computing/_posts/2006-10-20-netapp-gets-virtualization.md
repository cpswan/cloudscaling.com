---
title: 'NetApp gets Virtualization'
link: http://cloudscaling.com/blog/cloud-computing/technology/netapp-gets-virtualization/
author: randybias
description: 
post_id: 19
created: 2006/10/20 19:19:46
created_gmt: 2006/10/20 19:19:46
comment_status: open
post_name: netapp-gets-virtualization
status: publish
post_type: post
layout: post
category: cloud-computing
---

# NetApp gets Virtualization

NetApp's Founder, Dave Hitz, finally gets the [merits of virtualization](http://blogs.netapp.com/dave/TechTalk/?permalink=How-VMware-is-Revolutionizing-Data-Centers.html) in his excellent [blog](http://blogs.netapp.com/dave/). The reality is that virtualization is changing the way we think about IT in a fundamental way. There is one important facet of Dave's entry above I want to talk about for a moment. The principle of 'one application, one server.' Dave talks about this as an element of the Windows server world, which is unfortunately quite inaccurate. 'One application, one server' has less to do with the underlying OS and more to do with Best Practices in the IT world. The reality is that every IT practitioner wants to have a single application per server because it eases maintenance headaches, reduces complexity, and increases uptime. But wait, you say, doesn't more machines == more complexity?  No, in today's world, the complexity doesn't lie so much in managing machines and operating systems as it does in the applications that run on them. Pain exists more in dealing with multiple applications per machine than it does in managing the machine itself. An example will bring this home. Let's say you have a single monolithic server that provides file serving, printing, authentication, source code revision control, directory services, and more. If you need to perform maintenance on a single aspect of this system (e.g. the source code repository) that involves rebooting the system or otherwise impacting the availability of the machine you impact **every** service on that machine. Likewise, if you upgrade one aspect of that machine (e.g. the web server software) and that upgrade requires an updated shared library or DLL, the odds are you may impact another application that also uses that library. In an ideal world, the 'One Application, One Server' principle allows you to maximize uptime and minimize application conflicts by isolating applications from each other. Historically, the only reason to avoid this problem was a _scarcity of resources._ An issue that no longer exists. We now live in this ideal world where we literally have an overabundance of computation power, memory, and storage. Your average company running your average IT infrastructure easily affords 2-way or 4-way systems with 2+ GB of RAM and 100s of GBs of redundant storage to run something like Microsoft's Active Directory or Exchange for < 100 people. Microsoft's minimal [system requirements](http://www.microsoft.com/windowsserver2003/evaluation/sysreqs/default.mspx) for Windows Server 2003 R2 are a 133-Mhz processor with 128MB RAM; a 550Mhz processor and 256MB of RAM are recommended. This is for both Standard and Enterprise Editions. Of course, many/most Linux/UNIX requirements are likely even less. If you are following the principle of 'One Application, One Server', then the recommended requirements are certainly enough. _This trend towards an overabundance of computational power, memory, and storage is going to continue._ With this much abundance it only makes sense to isolate your applications from eachother and follow this principle. Virtualization technologies remove the scarcity issue. It is rapidly becoming the de facto standard to deployed virtualized IT servers, one application per server, regardless of OS. Nearly everyone I have talked to in the UNIX world is moving rapidly to Xen and the latest releases of key Linux distributions ship with it pre-installed and ready to go. Even Solaris, ships with it's own virtualization technology, [Solaris Zones](http://www.sun.com/bigadmin/content/zones/), now. Virtualization is here, it's real, and ultimately it is not about 'consolidation', but about reducing Operational Expense (OpEx). There are many folks leveraging this technology in exciting new ways for purposes that are hard to see today because we are still stuck thinking about machines as physical hardware. This is, fortunately, rapidly changing. If you are not today using virtualization, I strongly recommend at least experimenting with it in your infrastructure. I guarantee you will see immediate and important effects to your OpEx and management headaches. If not, I'll give you your money back. ;) \--Randy